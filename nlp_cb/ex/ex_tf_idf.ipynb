{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9114</th>\n",
       "      <td>i read after watching the film argued that it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13205</th>\n",
       "      <td>id love to see this campaign go viral to help ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15737</th>\n",
       "      <td>i still can t get over the fact that i feel ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>i didnt use to feel embarrassed walking by peo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14153</th>\n",
       "      <td>i feel i want to be carefree but all that is l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>i say whatever comes in my mind tell you direc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9443</th>\n",
       "      <td>i apologize to anyone who may feel i have been...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11193</th>\n",
       "      <td>i am tired of feeling unloved undesired unappr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8661</th>\n",
       "      <td>im already feeling less agitated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12131</th>\n",
       "      <td>i feel so unimportant to you now its not even ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  1\n",
       "9114   i read after watching the film argued that it ...  0\n",
       "13205  id love to see this campaign go viral to help ...  1\n",
       "15737  i still can t get over the fact that i feel ab...  1\n",
       "3268   i didnt use to feel embarrassed walking by peo...  2\n",
       "14153  i feel i want to be carefree but all that is l...  1\n",
       "159    i say whatever comes in my mind tell you direc...  0\n",
       "9443   i apologize to anyone who may feel i have been...  2\n",
       "11193  i am tired of feeling unloved undesired unappr...  2\n",
       "8661                    im already feeling less agitated  0\n",
       "12131  i feel so unimportant to you now its not even ...  2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../txt/train.txt', sep=';', header=None)\n",
    "df.drop(df[df[1] == 'surprise'].index, inplace = True)\n",
    "df.drop(df[df[1] == 'love'].index, inplace = True)\n",
    "df.drop(df[df[1] == 'fear'].index, inplace = True)\n",
    "\n",
    "df_anger = df[df[1] == 'anger']\n",
    "df_joy = df[df[1] == 'joy']\n",
    "df_joy = df_joy.sample(2159, random_state=2023)\n",
    "df_sadness = df[df[1] == 'sadness']\n",
    "df_sadness = df_sadness.sample(2159, random_state=2023)\n",
    "\n",
    "df2 = pd.concat([df_anger, df_joy, df_sadness])\n",
    "\n",
    "le = LabelEncoder()\n",
    "df2[1] = le.fit_transform(df2[1])\n",
    "\n",
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['preprocess_text'] = df2[0].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>preprocess_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>i feel kind of awkward about doing this here goes</td>\n",
       "      <td>2</td>\n",
       "      <td>feel kind awkward go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>i definitely feel there s some useful informat...</td>\n",
       "      <td>1</td>\n",
       "      <td>definitely feel s useful information face simi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>i feel lucky that theyve chosen to share their...</td>\n",
       "      <td>1</td>\n",
       "      <td>feel lucky ve choose share life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>i feel like i cant be respected if i have self...</td>\n",
       "      <td>1</td>\n",
       "      <td>feel like not respect self respect regular hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>i declined to purchase any this time i enjoyed...</td>\n",
       "      <td>1</td>\n",
       "      <td>decline purchase time enjoy feel squish projec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  1  \\\n",
       "551   i feel kind of awkward about doing this here goes  2   \n",
       "619   i definitely feel there s some useful informat...  1   \n",
       "708   i feel lucky that theyve chosen to share their...  1   \n",
       "227   i feel like i cant be respected if i have self...  1   \n",
       "1724  i declined to purchase any this time i enjoyed...  1   \n",
       "\n",
       "                                        preprocess_text  \n",
       "551                                feel kind awkward go  \n",
       "619   definitely feel s useful information face simi...  \n",
       "708                     feel lucky ve choose share life  \n",
       "227   feel like not respect self respect regular hat...  \n",
       "1724  decline purchase time enjoy feel squish projec...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('../txt/test.txt', header=None, sep=';')\n",
    "df_test.drop(df_test[df_test[1] == 'surprise'].index, inplace = True)\n",
    "df_test.drop(df_test[df_test[1] == 'love'].index, inplace = True)\n",
    "df_test.drop(df_test[df_test[1] == 'fear'].index, inplace = True)\n",
    "\n",
    "df_anger = df_test[df_test[1] == 'anger']\n",
    "df_joy = df_test[df_test[1] == 'joy']\n",
    "df_joy = df_joy.sample(275, random_state=2023)\n",
    "df_sadness = df_test[df_test[1] == 'sadness']\n",
    "df_sadness = df_sadness.sample(275, random_state=2023)\n",
    "\n",
    "df3 = pd.concat([df_anger, df_joy, df_sadness])\n",
    "\n",
    "le = LabelEncoder()\n",
    "df3[1] = le.fit_transform(df3[1])\n",
    "\n",
    "df3['preprocess_text'] = df3[0].apply(preprocess)\n",
    "\n",
    "df3.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       275\n",
      "           1       0.92      0.90      0.91       275\n",
      "           2       0.87      0.90      0.88       275\n",
      "\n",
      "    accuracy                           0.91       825\n",
      "   macro avg       0.91      0.91      0.91       825\n",
      "weighted avg       0.91      0.91      0.91       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('count_vectoriser', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=50))\n",
    "])\n",
    "\n",
    "clf.fit(df2['preprocess_text'], df2[1])\n",
    "\n",
    "y_pred = clf.predict(df3['preprocess_text'])\n",
    "\n",
    "print(classification_report(df3[1], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       275\n",
      "           1       0.89      0.96      0.92       275\n",
      "           2       0.94      0.85      0.89       275\n",
      "\n",
      "    accuracy                           0.92       825\n",
      "   macro avg       0.92      0.92      0.92       825\n",
      "weighted avg       0.92      0.92      0.92       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('count_vectoriser', TfidfVectorizer()),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=50))\n",
    "])\n",
    "\n",
    "clf.fit(df2['preprocess_text'], df2[1])\n",
    "\n",
    "y_pred = clf.predict(df3['preprocess_text'])\n",
    "\n",
    "print(classification_report(df3[1], y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
